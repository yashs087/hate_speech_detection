{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "shailja_mam_hate_dataset1(21022020).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOouLtf095NGe0JBVXU+0ah",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yashs087/hate_speech_detection/blob/master/shailja_mam_hate_dataset1(21022020).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qNuZglQz-49",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "#mport pickle\n",
        "#import sys\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer #vectorizer to change and test\n",
        "import nltk #natural language tool kit\n",
        "from nltk.stem.porter import *\n",
        "import string\n",
        "import re #regular expression\n",
        "#from textstat.textstat import *\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8KYB1BI57D3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdQKw_tL0tin",
        "colab_type": "code",
        "outputId": "506dcda8-a388-447f-e69f-49e80e0433a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "data= pd.read_csv(\"/content/dataset1.csv\")\n",
        "data.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   class                                              tweet\n",
              "0      2  !!! RT @mayasolovely: As a woman you shouldn't...\n",
              "1      1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...\n",
              "2      1  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...\n",
              "3      1  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...\n",
              "4      1  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYfvWzr0055i",
        "colab_type": "code",
        "outputId": "7a5d590c-9f03-40c9-fe05-9a0deab07824",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(data)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24783"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FVc30mz3ezI",
        "colab_type": "code",
        "outputId": "4faaa136-9e6a-4dcc-faab-ffded5d11e3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "set(data[\"class\"])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cu5X17Hm1XHr",
        "colab_type": "code",
        "outputId": "e324df38-30b5-4396-f36f-92ef373995b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "list(data[\"Label\"]).count(0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2898"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yBmL6Oq3JbO",
        "colab_type": "code",
        "outputId": "e2200df4-092e-45d8-913e-b9a5f9af4e55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "list(data[\"Label\"]).count(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1049"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJS9zJhR3vfx",
        "colab_type": "code",
        "outputId": "aec75b60-4b44-4ebd-9fb1-9984946134a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7SSh6vD4vJk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets = data.tweet\n",
        "\n",
        "stopwords=stopwords = nltk.corpus.stopwords.words(\"english\")  #removing stopwords for better performance\n",
        "\n",
        "stemmer = PorterStemmer() #algorithm for for removing the common morphological and inflexional endings from words in English.\n",
        "\n",
        "def preprocess(text_string):\n",
        "    \"\"\"\n",
        "    Accepts a text string and replaces:\n",
        "    1) urls with URLHERE\n",
        "    2) lots of whitespace with one instance\n",
        "    3) mentions with MENTIONHERE\n",
        "\n",
        "    This allows us to get standardized counts of urls and mentions\n",
        "    Without caring about specific people mentioned\n",
        "    \"\"\"\n",
        "    space_pattern = '\\s+'\n",
        "    giant_url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
        "                       '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
        "    mention_regex = '@[\\w\\-]+'\n",
        "    parsed_text = re.sub(space_pattern, ' ', text_string)\n",
        "    parsed_text = re.sub(giant_url_regex, '', parsed_text)\n",
        "    parsed_text = re.sub(mention_regex, '', parsed_text)\n",
        "    return parsed_text\n",
        "\n",
        "def tokenize(tweet):\n",
        "    \"\"\"Removes punctuation & excess whitespace, sets to lowercase,\n",
        "    and stems tweets. Returns a list of stemmed tokens.\"\"\"\n",
        "    tweet = \" \".join(re.split(\"[^a-zA-Z]*\", tweet.lower())).strip()\n",
        "    tokens = [stemmer.stem(t) for t in tweet.split() if t not in stopwords and len(t)> 2]\n",
        "    tokens = [t for t in tokens if len(t)>2]\n",
        "    return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUVISZR35HWh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer = TfidfVectorizer( #An alternative is to calculate word frequencies, and by far the most popular method is called TF-IDF\n",
        "    tokenizer=tokenize,\n",
        "    preprocessor=preprocess,\n",
        "    ngram_range=(1, 3), #an n-gram is a contiguous sequence of n items from a given sample of text\n",
        "    stop_words=stopwords,\n",
        "    use_idf=True,\n",
        "    smooth_idf=False,\n",
        "    norm=None,\n",
        "    decode_error='replace',\n",
        "    max_features=10000,\n",
        "    min_df=5,\n",
        "    max_df=0.75\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhWzd7YS5R8S",
        "colab_type": "code",
        "outputId": "bc72534a-a611-4cd3-d52b-2a57e382bd26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "tfidf=vectorizer.fit_transform(tweets).toarray()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
            "  return _compile(pattern, flags).split(string, maxsplit)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQRTcluA5Wg5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tfidf\n",
        "y = data['class'].astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Z8zqHvE5f3U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=42, test_size=0.35)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSq9vquX5l5M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifiers = [\n",
        "    LogisticRegression(),\n",
        "    LinearSVC(),\n",
        "    GaussianNB(),\n",
        "    SGDClassifier(),\n",
        "    KNeighborsClassifier(),\n",
        "    DecisionTreeClassifier(),\n",
        "    RandomForestClassifier(),\n",
        "    MLPClassifier()\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiQHMIiP6F0r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def df(report):\n",
        "    report_data = []\n",
        "    lines = report.split('\\n')\n",
        "    for line in lines[2:-3]:\n",
        "        row = {}\n",
        "        row_data = line.split('      ')\n",
        "        row['class'] = row_data[0]\n",
        "        row['precision'] = float(row_data[1])\n",
        "        row['recall'] = float(row_data[2])\n",
        "        row['f1_score'] = float(row_data[3])\n",
        "        row['support'] = float(row_data[4])\n",
        "        report_data.append(row)\n",
        "    dataframe = pd.DataFrame.from_dict(report_data)\n",
        "    return dataframe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Iw9qzAW6Jru",
        "colab_type": "code",
        "outputId": "89340c47-07fc-4bc5-fb46-1e1ad3778abe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "Results=[]\n",
        "for i,item in enumerate(classifiers):\n",
        "    clf = item\n",
        "    clf.fit(X_train, y_train)\n",
        "    print(item,'\\n')\n",
        "    y_preds = clf.predict(X_test)\n",
        "    report = classification_report( y_test, y_preds,output_dict=True)\n",
        "    Results.append(report)\n",
        "    print(report,\"\\n\")\n",
        "    print(confusion_matrix(y_test, y_preds),\"\\n\\n\\n\")\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False) \n",
            "\n",
            "{'0': {'precision': 0.27230046948356806, 'recall': 0.23673469387755103, 'f1-score': 0.25327510917030566, 'support': 490}, '1': {'precision': 0.9000144279324773, 'recall': 0.9281356940931409, 'f1-score': 0.9138587752710225, 'support': 6721}, '2': {'precision': 0.8042488619119879, 'recall': 0.7240437158469946, 'f1-score': 0.762041696621136, 'support': 1464}, 'accuracy': 0.8546397694524496, 'macro avg': {'precision': 0.6588545864426777, 'recall': 0.6296380346058955, 'f1-score': 0.6430585270208214, 'support': 8675}, 'weighted avg': {'precision': 0.8483970644403779, 'recall': 0.8546397694524496, 'f1-score': 0.8509254957859753, 'support': 8675}} \n",
            "\n",
            "[[ 116  335   39]\n",
            " [ 264 6238  219]\n",
            " [  46  358 1060]] \n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
            "          verbose=0) \n",
            "\n",
            "{'0': {'precision': 0.19814814814814816, 'recall': 0.21836734693877552, 'f1-score': 0.20776699029126214, 'support': 490}, '1': {'precision': 0.8884345794392523, 'recall': 0.9052224371373307, 'f1-score': 0.8967499447269511, 'support': 6721}, '2': {'precision': 0.7544677544677545, 'recall': 0.6632513661202186, 'f1-score': 0.7059251181388586, 'support': 1464}, 'accuracy': 0.8255907780979828, 'macro avg': {'precision': 0.613683494018385, 'recall': 0.5956137167321083, 'f1-score': 0.6034806843856907, 'support': 8675}, 'weighted avg': {'precision': 0.8268359877284841, 'recall': 0.8255907780979828, 'f1-score': 0.8256295765657459, 'support': 8675}} \n",
            "\n",
            "[[ 107  343   40]\n",
            " [ 361 6084  276]\n",
            " [  72  421  971]] \n",
            "\n",
            "\n",
            "\n",
            "GaussianNB(priors=None, var_smoothing=1e-09) \n",
            "\n",
            "{'0': {'precision': 0.09760589318600368, 'recall': 0.4326530612244898, 'f1-score': 0.15927873779113447, 'support': 490}, '1': {'precision': 0.8927218344965104, 'recall': 0.6661211129296236, 'f1-score': 0.7629516019086572, 'support': 6721}, '2': {'precision': 0.5504032258064516, 'recall': 0.5594262295081968, 'f1-score': 0.5548780487804879, 'support': 1464}, 'accuracy': 0.63492795389049, 'macro avg': {'precision': 0.5135769844963219, 'recall': 0.5527334678874367, 'f1-score': 0.4923694628267598, 'support': 8675}, 'weighted avg': {'precision': 0.7900404218896638, 'recall': 0.63492795389049, 'f1-score': 0.6937389926640201, 'support': 8675}} \n",
            "\n",
            "[[ 212  206   72]\n",
            " [1647 4477  597]\n",
            " [ 313  332  819]] \n",
            "\n",
            "\n",
            "\n",
            "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
            "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
            "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
            "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
            "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
            "              validation_fraction=0.1, verbose=0, warm_start=False) \n",
            "\n",
            "{'0': {'precision': 0.2632850241545894, 'recall': 0.22244897959183674, 'f1-score': 0.2411504424778761, 'support': 490}, '1': {'precision': 0.897082075607302, 'recall': 0.9285820562416307, 'f1-score': 0.9125603158356485, 'support': 6721}, '2': {'precision': 0.7937116564417178, 'recall': 0.7069672131147541, 'f1-score': 0.7478323699421965, 'support': 1464}, 'accuracy': 0.8512968299711815, 'macro avg': {'precision': 0.651359585401203, 'recall': 0.6193327496494071, 'f1-score': 0.6338477094185737, 'support': 8675}, 'weighted avg': {'precision': 0.8438377126251412, 'recall': 0.8512968299711815, 'f1-score': 0.8468366788635076, 'support': 8675}} \n",
            "\n",
            "[[ 109  341   40]\n",
            " [ 251 6241  229]\n",
            " [  54  375 1035]] \n",
            "\n",
            "\n",
            "\n",
            "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
            "                     weights='uniform') \n",
            "\n",
            "{'0': {'precision': 0.46859903381642515, 'recall': 0.19795918367346937, 'f1-score': 0.2783357245337159, 'support': 490}, '1': {'precision': 0.8610515021459227, 'recall': 0.9552149977681893, 'f1-score': 0.9056923185441208, 'support': 6721}, '2': {'precision': 0.775691699604743, 'recall': 0.5362021857923497, 'f1-score': 0.6340872374798061, 'support': 1464}, 'accuracy': 0.8417291066282421, 'macro avg': {'precision': 0.7017807451890303, 'recall': 0.5631254557446694, 'f1-score': 0.6060384268525476, 'support': 8675}, 'weighted avg': {'precision': 0.8244787689584022, 'recall': 0.8417291066282421, 'f1-score': 0.8244203220319299, 'support': 8675}} \n",
            "\n",
            "[[  97  365   28]\n",
            " [ 102 6420  199]\n",
            " [   8  671  785]] \n",
            "\n",
            "\n",
            "\n",
            "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
            "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=None, splitter='best') \n",
            "\n",
            "{'0': {'precision': 0.32105263157894737, 'recall': 0.24897959183673468, 'f1-score': 0.28045977011494255, 'support': 490}, '1': {'precision': 0.9063762261973456, 'recall': 0.934831126320488, 'f1-score': 0.9203837984325789, 'support': 6721}, '2': {'precision': 0.8107116654438739, 'recall': 0.7547814207650273, 'f1-score': 0.7817474354439335, 'support': 1464}, 'accuracy': 0.8657060518731988, 'macro avg': {'precision': 0.6793801744067222, 'recall': 0.64619737964075, 'f1-score': 0.6608636679971517, 'support': 8675}, 'weighted avg': {'precision': 0.8571702920986599, 'recall': 0.8657060518731988, 'f1-score': 0.860841849234767, 'support': 8675}} \n",
            "\n",
            "[[ 122  325   43]\n",
            " [ 223 6283  215]\n",
            " [  35  324 1105]] \n",
            "\n",
            "\n",
            "\n",
            "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False) \n",
            "\n",
            "{'0': {'precision': 0.4842105263157895, 'recall': 0.18775510204081633, 'f1-score': 0.2705882352941177, 'support': 490}, '1': {'precision': 0.911530815109344, 'recall': 0.9550662103853593, 'f1-score': 0.9327908159558236, 'support': 6721}, '2': {'precision': 0.8205128205128205, 'recall': 0.8087431693989071, 'f1-score': 0.8145854833161335, 'support': 1464}, 'accuracy': 0.8870317002881845, 'macro avg': {'precision': 0.7387513873126513, 'recall': 0.6505214939416942, 'f1-score': 0.6726548448553582, 'support': 8675}, 'weighted avg': {'precision': 0.8720337216686349, 'recall': 0.8870317002881845, 'f1-score': 0.8754384388366602, 'support': 8675}} \n",
            "\n",
            "[[  92  352   46]\n",
            " [  89 6419  213]\n",
            " [   9  271 1184]] \n",
            "\n",
            "\n",
            "\n",
            "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
            "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
            "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
            "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
            "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
            "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
            "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
            "              warm_start=False) \n",
            "\n",
            "{'0': {'precision': 0.30847457627118646, 'recall': 0.18571428571428572, 'f1-score': 0.2318471337579618, 'support': 490}, '1': {'precision': 0.8963466440101954, 'recall': 0.941824133313495, 'f1-score': 0.9185228179641587, 'support': 6721}, '2': {'precision': 0.7996965098634294, 'recall': 0.7199453551912568, 'f1-score': 0.757728253055356, 'support': 1464}, 'accuracy': 0.861671469740634, 'macro avg': {'precision': 0.668172576714937, 'recall': 0.6158279247396793, 'f1-score': 0.6360327349258255, 'support': 8675}, 'weighted avg': {'precision': 0.8468304354127338, 'recall': 0.861671469740634, 'f1-score': 0.8526007051932626, 'support': 8675}} \n",
            "\n",
            "[[  91  358   41]\n",
            " [ 168 6330  223]\n",
            " [  36  374 1054]] \n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQZ9Fa7j6RTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr=pd.DataFrame(Results[0]).transpose()\n",
        "svc=pd.DataFrame(Results[1]).transpose()\n",
        "gnb=pd.DataFrame(Results[2]).transpose()\n",
        "sgd=pd.DataFrame(Results[3]).transpose()\n",
        "knn=pd.DataFrame(Results[4]).transpose()\n",
        "tree=pd.DataFrame(Results[5]).transpose()\n",
        "forest=pd.DataFrame(Results[6]).transpose()\n",
        "mlp=pd.DataFrame(Results[7]).transpose()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr6_XhiL6X3N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = pd.concat([lr,svc,gnb,sgd,knn,tree,forest,mlp], keys=['LogisticRegression','LinearSVC','GaussianNB','SGDClassifier','KNeighborsClassifier','DecisionTreeClassifier','RandomForestClassifier','MLPClassifier'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bh_9rsKL6Zbg",
        "colab_type": "code",
        "outputId": "c98a232d-f838-4b7d-95bd-190025a3fc63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "result"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"6\" valign=\"top\">LogisticRegression</th>\n",
              "      <th>0</th>\n",
              "      <td>0.272300</td>\n",
              "      <td>0.236735</td>\n",
              "      <td>0.253275</td>\n",
              "      <td>490.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.900014</td>\n",
              "      <td>0.928136</td>\n",
              "      <td>0.913859</td>\n",
              "      <td>6721.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.804249</td>\n",
              "      <td>0.724044</td>\n",
              "      <td>0.762042</td>\n",
              "      <td>1464.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>accuracy</th>\n",
              "      <td>0.854640</td>\n",
              "      <td>0.854640</td>\n",
              "      <td>0.854640</td>\n",
              "      <td>0.854640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>macro avg</th>\n",
              "      <td>0.658855</td>\n",
              "      <td>0.629638</td>\n",
              "      <td>0.643059</td>\n",
              "      <td>8675.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weighted avg</th>\n",
              "      <td>0.848397</td>\n",
              "      <td>0.854640</td>\n",
              "      <td>0.850925</td>\n",
              "      <td>8675.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"6\" valign=\"top\">LinearSVC</th>\n",
              "      <th>0</th>\n",
              "      <td>0.198148</td>\n",
              "      <td>0.218367</td>\n",
              "      <td>0.207767</td>\n",
              "      <td>490.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.888435</td>\n",
              "      <td>0.905222</td>\n",
              "      <td>0.896750</td>\n",
              "      <td>6721.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.754468</td>\n",
              "      <td>0.663251</td>\n",
              "      <td>0.705925</td>\n",
              "      <td>1464.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>accuracy</th>\n",
              "      <td>0.825591</td>\n",
              "      <td>0.825591</td>\n",
              "      <td>0.825591</td>\n",
              "      <td>0.825591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>macro avg</th>\n",
              "      <td>0.613683</td>\n",
              "      <td>0.595614</td>\n",
              "      <td>0.603481</td>\n",
              "      <td>8675.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weighted avg</th>\n",
              "      <td>0.826836</td>\n",
              "      <td>0.825591</td>\n",
              "      <td>0.825630</td>\n",
              "      <td>8675.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"6\" valign=\"top\">GaussianNB</th>\n",
              "      <th>0</th>\n",
              "      <td>0.097606</td>\n",
              "      <td>0.432653</td>\n",
              "      <td>0.159279</td>\n",
              "      <td>490.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.892722</td>\n",
              "      <td>0.666121</td>\n",
              "      <td>0.762952</td>\n",
              "      <td>6721.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.550403</td>\n",
              "      <td>0.559426</td>\n",
              "      <td>0.554878</td>\n",
              "      <td>1464.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>accuracy</th>\n",
              "      <td>0.634928</td>\n",
              "      <td>0.634928</td>\n",
              "      <td>0.634928</td>\n",
              "      <td>0.634928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>macro avg</th>\n",
              "      <td>0.513577</td>\n",
              "      <td>0.552733</td>\n",
              "      <td>0.492369</td>\n",
              "      <td>8675.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weighted avg</th>\n",
              "      <td>0.790040</td>\n",
              "      <td>0.634928</td>\n",
              "      <td>0.693739</td>\n",
              "      <td>8675.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"6\" valign=\"top\">SGDClassifier</th>\n",
              "      <th>0</th>\n",
              "      <td>0.263285</td>\n",
              "      <td>0.222449</td>\n",
              "      <td>0.241150</td>\n",
              "      <td>490.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.897082</td>\n",
              "      <td>0.928582</td>\n",
              "      <td>0.912560</td>\n",
              "      <td>6721.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.793712</td>\n",
              "      <td>0.706967</td>\n",
              "      <td>0.747832</td>\n",
              "      <td>1464.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>accuracy</th>\n",
              "      <td>0.851297</td>\n",
              "      <td>0.851297</td>\n",
              "      <td>0.851297</td>\n",
              "      <td>0.851297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>macro avg</th>\n",
              "      <td>0.651360</td>\n",
              "      <td>0.619333</td>\n",
              "      <td>0.633848</td>\n",
              "      <td>8675.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weighted avg</th>\n",
              "      <td>0.843838</td>\n",
              "      <td>0.851297</td>\n",
              "      <td>0.846837</td>\n",
              "      <td>8675.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"6\" valign=\"top\">KNeighborsClassifier</th>\n",
              "      <th>0</th>\n",
              "      <td>0.468599</td>\n",
              "      <td>0.197959</td>\n",
              "      <td>0.278336</td>\n",
              "      <td>490.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.861052</td>\n",
              "      <td>0.955215</td>\n",
              "      <td>0.905692</td>\n",
              "      <td>6721.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.775692</td>\n",
              "      <td>0.536202</td>\n",
              "      <td>0.634087</td>\n",
              "      <td>1464.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>accuracy</th>\n",
              "      <td>0.841729</td>\n",
              "      <td>0.841729</td>\n",
              "      <td>0.841729</td>\n",
              "      <td>0.841729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>macro avg</th>\n",
              "      <td>0.701781</td>\n",
              "      <td>0.563125</td>\n",
              "      <td>0.606038</td>\n",
              "      <td>8675.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weighted avg</th>\n",
              "      <td>0.824479</td>\n",
              "      <td>0.841729</td>\n",
              "      <td>0.824420</td>\n",
              "      <td>8675.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"6\" valign=\"top\">DecisionTreeClassifier</th>\n",
              "      <th>0</th>\n",
              "      <td>0.321053</td>\n",
              "      <td>0.248980</td>\n",
              "      <td>0.280460</td>\n",
              "      <td>490.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.906376</td>\n",
              "      <td>0.934831</td>\n",
              "      <td>0.920384</td>\n",
              "      <td>6721.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.810712</td>\n",
              "      <td>0.754781</td>\n",
              "      <td>0.781747</td>\n",
              "      <td>1464.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>accuracy</th>\n",
              "      <td>0.865706</td>\n",
              "      <td>0.865706</td>\n",
              "      <td>0.865706</td>\n",
              "      <td>0.865706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>macro avg</th>\n",
              "      <td>0.679380</td>\n",
              "      <td>0.646197</td>\n",
              "      <td>0.660864</td>\n",
              "      <td>8675.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weighted avg</th>\n",
              "      <td>0.857170</td>\n",
              "      <td>0.865706</td>\n",
              "      <td>0.860842</td>\n",
              "      <td>8675.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"6\" valign=\"top\">RandomForestClassifier</th>\n",
              "      <th>0</th>\n",
              "      <td>0.484211</td>\n",
              "      <td>0.187755</td>\n",
              "      <td>0.270588</td>\n",
              "      <td>490.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.911531</td>\n",
              "      <td>0.955066</td>\n",
              "      <td>0.932791</td>\n",
              "      <td>6721.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.820513</td>\n",
              "      <td>0.808743</td>\n",
              "      <td>0.814585</td>\n",
              "      <td>1464.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>accuracy</th>\n",
              "      <td>0.887032</td>\n",
              "      <td>0.887032</td>\n",
              "      <td>0.887032</td>\n",
              "      <td>0.887032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>macro avg</th>\n",
              "      <td>0.738751</td>\n",
              "      <td>0.650521</td>\n",
              "      <td>0.672655</td>\n",
              "      <td>8675.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weighted avg</th>\n",
              "      <td>0.872034</td>\n",
              "      <td>0.887032</td>\n",
              "      <td>0.875438</td>\n",
              "      <td>8675.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"6\" valign=\"top\">MLPClassifier</th>\n",
              "      <th>0</th>\n",
              "      <td>0.308475</td>\n",
              "      <td>0.185714</td>\n",
              "      <td>0.231847</td>\n",
              "      <td>490.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.896347</td>\n",
              "      <td>0.941824</td>\n",
              "      <td>0.918523</td>\n",
              "      <td>6721.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.799697</td>\n",
              "      <td>0.719945</td>\n",
              "      <td>0.757728</td>\n",
              "      <td>1464.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>accuracy</th>\n",
              "      <td>0.861671</td>\n",
              "      <td>0.861671</td>\n",
              "      <td>0.861671</td>\n",
              "      <td>0.861671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>macro avg</th>\n",
              "      <td>0.668173</td>\n",
              "      <td>0.615828</td>\n",
              "      <td>0.636033</td>\n",
              "      <td>8675.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weighted avg</th>\n",
              "      <td>0.846830</td>\n",
              "      <td>0.861671</td>\n",
              "      <td>0.852601</td>\n",
              "      <td>8675.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     precision    recall  f1-score      support\n",
              "LogisticRegression     0              0.272300  0.236735  0.253275   490.000000\n",
              "                       1              0.900014  0.928136  0.913859  6721.000000\n",
              "                       2              0.804249  0.724044  0.762042  1464.000000\n",
              "                       accuracy       0.854640  0.854640  0.854640     0.854640\n",
              "                       macro avg      0.658855  0.629638  0.643059  8675.000000\n",
              "                       weighted avg   0.848397  0.854640  0.850925  8675.000000\n",
              "LinearSVC              0              0.198148  0.218367  0.207767   490.000000\n",
              "                       1              0.888435  0.905222  0.896750  6721.000000\n",
              "                       2              0.754468  0.663251  0.705925  1464.000000\n",
              "                       accuracy       0.825591  0.825591  0.825591     0.825591\n",
              "                       macro avg      0.613683  0.595614  0.603481  8675.000000\n",
              "                       weighted avg   0.826836  0.825591  0.825630  8675.000000\n",
              "GaussianNB             0              0.097606  0.432653  0.159279   490.000000\n",
              "                       1              0.892722  0.666121  0.762952  6721.000000\n",
              "                       2              0.550403  0.559426  0.554878  1464.000000\n",
              "                       accuracy       0.634928  0.634928  0.634928     0.634928\n",
              "                       macro avg      0.513577  0.552733  0.492369  8675.000000\n",
              "                       weighted avg   0.790040  0.634928  0.693739  8675.000000\n",
              "SGDClassifier          0              0.263285  0.222449  0.241150   490.000000\n",
              "                       1              0.897082  0.928582  0.912560  6721.000000\n",
              "                       2              0.793712  0.706967  0.747832  1464.000000\n",
              "                       accuracy       0.851297  0.851297  0.851297     0.851297\n",
              "                       macro avg      0.651360  0.619333  0.633848  8675.000000\n",
              "                       weighted avg   0.843838  0.851297  0.846837  8675.000000\n",
              "KNeighborsClassifier   0              0.468599  0.197959  0.278336   490.000000\n",
              "                       1              0.861052  0.955215  0.905692  6721.000000\n",
              "                       2              0.775692  0.536202  0.634087  1464.000000\n",
              "                       accuracy       0.841729  0.841729  0.841729     0.841729\n",
              "                       macro avg      0.701781  0.563125  0.606038  8675.000000\n",
              "                       weighted avg   0.824479  0.841729  0.824420  8675.000000\n",
              "DecisionTreeClassifier 0              0.321053  0.248980  0.280460   490.000000\n",
              "                       1              0.906376  0.934831  0.920384  6721.000000\n",
              "                       2              0.810712  0.754781  0.781747  1464.000000\n",
              "                       accuracy       0.865706  0.865706  0.865706     0.865706\n",
              "                       macro avg      0.679380  0.646197  0.660864  8675.000000\n",
              "                       weighted avg   0.857170  0.865706  0.860842  8675.000000\n",
              "RandomForestClassifier 0              0.484211  0.187755  0.270588   490.000000\n",
              "                       1              0.911531  0.955066  0.932791  6721.000000\n",
              "                       2              0.820513  0.808743  0.814585  1464.000000\n",
              "                       accuracy       0.887032  0.887032  0.887032     0.887032\n",
              "                       macro avg      0.738751  0.650521  0.672655  8675.000000\n",
              "                       weighted avg   0.872034  0.887032  0.875438  8675.000000\n",
              "MLPClassifier          0              0.308475  0.185714  0.231847   490.000000\n",
              "                       1              0.896347  0.941824  0.918523  6721.000000\n",
              "                       2              0.799697  0.719945  0.757728  1464.000000\n",
              "                       accuracy       0.861671  0.861671  0.861671     0.861671\n",
              "                       macro avg      0.668173  0.615828  0.636033  8675.000000\n",
              "                       weighted avg   0.846830  0.861671  0.852601  8675.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    }
  ]
}